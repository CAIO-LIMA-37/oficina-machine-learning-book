[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning com Python e R: Decision Trees & Random Forests",
    "section": "",
    "text": "1 Autor\nSou fascinado pela área de Inteligência Artificial, com ênfase em Aprendizado de Máquina, Aprendizad Profundo, IA Generativa e Agentes de IA. Paralelamente, dedico-me ao estudo da Teoria do Cálculo e Teoria das Probabilidades, com foco em compreender suas estruturas formais, demonstrações e aplicações.\nMe considero um teórico-empirista, dividindo meu enfoque entre 60% de dedicação à teoria pura e 40% à prática aplicada. Também tenho interesse pelas áreas de Processamento de Linguagem Natural e Visão Computacional, explorando caminhos para o desenvolvimento de sistemas autossuficientes e adaptativos. Tenho uma forte motivação para entender como algoritmos aprendem com dados e como podem ser usados para resolver problemas reais.\nAtualmente, sou bolsista PIBIC no projeto de pesquisa intitulado “Técnicas de IA Generativa para Construção de Sistemas Baseados em Large Language Models”, sob orientação do Prof. Dr. Aldebaro Barreto da Rocha Klautau Júnior, vinculado ao Instituto de Tecnologia (ITEC) e ao laboratório LASSE.\nO foco da pesquisa é o desenvolvimento de sistemas baseados em LLMs que integram métodos como Retrieval-Augmented Generation e LangGraph, para criação de agentes autônomos aplicáveis em telecomunicações.\nAlém do foco em IA, também desenvolvo estudos em Econometria, com ênfase na Teoria Hedônica aplicada ao Mercado Imobiliário — área que busca modelar o valor de bens a partir de suas características intrínsecas, sob orientação da Profª Dr. Marinalva Cardoso Maciel. Acredito que a interação entre Estatística, Econometria e Machine Learning abre portas para análises mais robustas e aplicações práticas em mercados complexos, como o imobiliário.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Apresentação</span>"
    ]
  },
  {
    "objectID": "index.html#nome-machine-learning-com-python-e-r-árvores-de-decisão-e-random-forests",
    "href": "index.html#nome-machine-learning-com-python-e-r-árvores-de-decisão-e-random-forests",
    "title": "Machine Learning com Python e R: Decision Trees & Random Forests",
    "section": "2.1 Nome: Machine Learning com Python e R – Árvores de Decisão e Random Forests",
    "text": "2.1 Nome: Machine Learning com Python e R – Árvores de Decisão e Random Forests\nEsta oficina tem como objetivo apresentar conceitos fundamentais de Inteligência Artificial e Aprendizado de Máquina, com ênfase prática em Árvores de Decisão e Random Forests, utilizando Python e R como linguagens base.\nDurante os quatro dias de oficina, serão abordados tanto os fundamentos teóricos quanto a implementação prática dos modelos, passando pelas etapas essenciais de um pipeline de Machine Learning: desde a coleta e pré-processamento dos dados até a avaliação de desempenho dos modelos.\nA oficina é voltada para alunos de graduação com conhecimentos básicos em programação e estatística, especialmente aqueles dos semestres finais ou intermediários, interessados em aplicações reais da Estatística e da IA.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Apresentação</span>"
    ]
  },
  {
    "objectID": "index.html#abordagem-didática",
    "href": "index.html#abordagem-didática",
    "title": "Machine Learning com Python e R: Decision Trees & Random Forests",
    "section": "2.2 Abordagem Didática",
    "text": "2.2 Abordagem Didática\nA estrutura da oficina está dividida em módulos:\n\n\n  \n  \n  Oficina de Machine Learning\n  \n\n\n\n  \n    Oficina de Machine Learning\n\n    \n      Dia 1: Fundamentos\n      Objetivo: Pegar a estrada com o pé direito, entendendo os conceitos-chave e preparando os dados.\n      \n        De onde vem o ML no universo da IA? (DL, RL, IA Generativa)\n        Quando usar aprendizado supervisionado vs. não supervisionado?\n        Pré-processamento inteligente: desde dados faltantes até seleção de features importantes.\n      \n    \n\n    \n      Dia 2: Árvores de Decisão\n      Objetivo: Dominar os algoritmos clássicos e aprender a diagnosticar seus modelos.\n      \n        CART e ID3 passo a passo – como a árvore \"pensa\"?\n        Avaliação de modelos: acurácia, precisão, recall... qual métrica usar?\n        Problemas comuns: overfitting, underfitting e o equilíbrio entre viés e variância.\n      \n    \n\n    \n      Dia 3: Otimização e Regularização\n      Objetivo: Aprender técnicas para deixar seus modelos mais robustos.\n      \n        Tuning de hiperparâmetros: GridSearch vs. RandomSearch\n        Regularização em árvores: como evitar modelos muito complexos?\n        CHAID: árvores para segmentação avançada\n        Comparando modelos: Curva ROC, AUC, MSE e mais\n        Primeiro contato com Ensemble Learning\n      \n    \n\n    \n      Dia 4: Ensemble Learning e Florestas Aleatórias\n      Objetivo: Combinar modelos para resultados melhores!\n      \n        Bagging vs. Pasting: qual a diferença e quando usar?\n        Florestas Aleatórias na prática – por que elas são tão poderosas?\n        Boosting: AdaBoost e Gradient Boosting\n        Stacking: juntando modelos diferentes pra ganhar performance\n      \n    \n\n    \n      Precisa saber o quê pra fazer a oficina?\n\n      \n        Programação:\n        \n          Se você já manja o básico de Python ou R (sabe o que é e como manipular um loop, uma função, um DataFrame), tá pronto!\n          Experiência com bibliotecas como Pandas, NumPy (Python) ou dplyr, tidyr (R).\n        \n      \n\n      \n        Matemática e Estatística:\n        \n          Noções básicas de probabilidade, teste de hipótese e estatística descritiva (média, desvio padrão, distribuições).\n          Conceitos introdutórios de otimização (gradiente, funções de custo) são úteis, mas não obrigatórios.\n        \n      \n    \n\n  \n\n\n\n\nAo final da oficina, os participantes terão não apenas compreendido os fundamentos de Árvores de Decisão e Random Forests, mas também serão capazes de aplicar esses modelos em dados reais, utilizando pipelines completos em Python ou R, com uma visão crítica e estatística sobre os resultados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Apresentação</span>"
    ]
  },
  {
    "objectID": "modulo_1.html",
    "href": "modulo_1.html",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "",
    "text": "3 De Machine Learning a Agentes de IA: Uma Linha Evolutiva\nO campo da Inteligência Artificial (IA) está fundamentalmente preocupado não apenas com a compreensão, mas também com a construção de entidades inteligentes. Essas entidades são máquinas projetadas para calcular como agir de forma eficaz e segura em uma ampla variedade de situações novas. A própria ideia de inteligência é central para a nossa identidade como Homo sapiens – “homem sábio” – e, por milênios, temos buscado entender como pensamos e agimos, ou seja, como o cérebro pode perceber, compreender, prever e manipular um mundo muito maior e mais complexo do que ele mesmo, como descrevem Norvig & Russell (2021).\nNo livro Artificial Intelligence: A Modern Approach, os autores adotam a perspectiva da racionalidade como tema unificador. Segundo o que é chamado de modelo padrão, a IA se preocupa principalmente com a ação racional. Um agente inteligente ideal toma a melhor ação possível em uma situação. A abordagem do livro estuda o problema de construir agentes que são inteligentes neste sentido.\nDefine-se IA como o estudo de agentes que recebem percepções do ambiente e executam ações. Cada agente implementa uma função que mapeia sequências de percepção para ações. A noção de racionalidade pode ser aplicada a uma ampla variedade de agentes operando em qualquer ambiente imaginável. A ideia central é usar esse conceito para desenvolver um conjunto pequeno de princípios de design para a construção de agentes bem-sucedidos.\nUm agente racional age para alcançar seus objetivos, dada a informação percebida. A racionalidade se relaciona com a forma como um agente toma decisões em seu ambiente. Para agir racionalmente, um agente precisa ser capaz de:\nTuring considerava que a simulação física de uma pessoa não era essencial para demonstrar inteligência. Entretanto, outros pesquisadores propuseram um Teste de Turing total, que exige interação com objetos e pessoas no mundo real. Para ser aprovado no Teste de Turing total, um robô necessitaria de:\nÉ importante notar que Aprendizado de Máquina (Machine Learning) é um subcampo da IA que estuda a capacidade de melhorar o desempenho com base na experiência. Embora alguns sistemas de IA usem métodos de aprendizado de máquina para alcançar competência, outros não. O aprendizado é enfatizado tanto como um método de construção para sistemas competentes quanto como uma forma de estender o alcance do projetista em ambientes desconhecidos. Todos os agentes podem melhorar seu desempenho através do aprendizado.\nA jornada da Inteligência Artificial (IA) é uma progressão fascinante. Tudo começou com o Machine Learning (Aprendizado de Máquina) em meados do século XX, focados em algoritmos e modelos que aprendiam padrões em dados para fazer previsões e classificações, sem programação explícita.\nCom o tempo e o aumento do poder computacional, o Deep Learning (Aprendizado Profundo) emergiu. Utilizando redes neurais multicamadas, ele revolucionou a capacidade das máquinas de aprender representações complexas de dados, impulsionando avanços em visão computacional e processamento de linguagem.\nMais recentemente, a IA Generativa surgiu, permitindo que modelos de Deep Learning criem conteúdo original – como textos e imagens – a partir de dados de treinamento, indo além da previsão e classificação.\nEssa evolução culmina nos Agentes de IA: sistemas que integram aprendizado, geração, percepção, raciocínio e planejamento para agir de forma autônoma em ambientes complexos. Eles representam o auge dessa linha evolutiva, onde a inteligência artificial ganha capacidade de ação e autonomia.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#machine-learning-aprendizado-de-máquina-e-statistical-learning-aprendizado-estatístico",
    "href": "modulo_1.html#machine-learning-aprendizado-de-máquina-e-statistical-learning-aprendizado-estatístico",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "3.1 Machine Learning (Aprendizado de Máquina) e Statistical Learning (Aprendizado Estatístico)",
    "text": "3.1 Machine Learning (Aprendizado de Máquina) e Statistical Learning (Aprendizado Estatístico)\nDe acordo com a perspectiva apresentada em “Artificial Intelligence: A Modern Approach”, um agente é considerado em aprendizado (learning) se ele melhora seu desempenho após fazer observações sobre o mundo. Quando esse agente é um computador, isso é denominado Machine Learning (ML) (Norvig & Russell, 2021). Em ML, em vez de criar um programa com regras explícitas para mapear entradas para saídas, define-se um programa flexível cujo comportamento é determinado por parâmetros. Um conjunto de dados é utilizado para determinar os melhores valores desses parâmetros, visando aprimorar o desempenho do programa. Isso é conceitualizado como “programar com dados”.\nParalelamente e de forma interligada, existe o campo do Aprendizado Estatístico (Statistical Learning). Autores como Pedro Alberto Morettin e Julio da Motta Singer o associam à utilização de modelos estatísticos acoplados a algoritmos computacionais para extrair informação de conjuntos de dados, frequentemente volumosos. V. Vapnik e Alexey Chernovenkis foram, possivelmente, os primeiros a empregar o termo “Aprendizado com Estatística” (Statistical Learning) no contexto de problemas de reconhecimento de padrões e inteligência artificial (Morettin & Singer, 2024).\n\n3.1.1 Similaridades e Diferenças sob a Perspectiva dos Autores:\n\nOs autores Hastie et al. (2009), estatísticos por formação, declaram terem sido “fortemente influenciados” por campos como redes neurais, mineração de dados e ML. Eles apresentam muitos métodos populares em ML (como Support Vector Machines - SVM, redes neurais, e métodos baseados em árvores como CART por Breiman) dentro da estrutura do Aprendizado Estatístico, e o subtítulo de The Elements of Statistical Learning é “Data Mining, Inference, and Prediction”. Isso indica que veem o ML como um campo cujos métodos podem ser integrados e compreendidos a partir de um ponto de vista estatístico. A necessidade de um tratamento mais acessível desses tópicos levou ao desenvolvimento e publicação, pelos mesmo autores, de livros como Introduction to Statistical Learning, With Applications in R em 2013, com segunda edição em 2021, e An Introduction to Statistical Learning, With Applications in Python em 2023 (James et al., 2021), (James et al., 2023).\nMorettin e Singer, estatísticos, observam que grande parte do que hoje é chamado Ciência de Dados e Aprendizado Automático (Machine Learning) consiste na aplicação de técnicas estatísticas que, em muitos casos, já existiam há décadas, mas cuja aplicação em larga escala só se tornou viável com o avanço da capacidade computacional recente. Eles explicitamente usam os termos “Aprendizado Estatística” e “Machine Learning” em conjunto, afirmando que tratam dos mesmos tópicos, com diferenças de interpretação pela abordagem e objetivo (Morettin & Singer, 2024).\nUma diferença fundamental de foco é apontada por Morettin e Singer. Enquanto a Estatística tradicional frequentemente se concentra em entender a associação entre variáveis preditoras e a variável resposta, teste de hipóteses e intervalo de confiança (inferência estatística), o objetivo do ML é, muitas vezes, selecionar o modelo que produz as melhores previsões ou classificações, mesmo que o modelo tenha baixa interpretabilidade (Morettin & Singer, 2024), (James et al., 2021).\n\nEm suma, os autores retratam Machine Learning (ML) e Statistical Learning como campos profundamente interligados e sobrepostos, compartilhando métodos e objetivos de aprender com dados, construir modelos e fazer previsões ou extrair estruturas. O Aprendizado Estatístico pode ser visto como a estrutura estatística subjacente a muitos métodos de ML, com uma tradição que abrange tanto a inferência quanto a previsão/classificação e descoberta de padrões. O ML, impulsionado pela capacidade computacional e com forte ligação à IA e Ciência da Computação, frequentemente enfatiza o desempenho preditivo e a aplicação de algoritmos a grandes conjuntos de dados. No entanto, as fontes deixam claro que muitos dos métodos utilizados em ML são técnicas estatísticas que foram revitalizadas e tornaram-se aplicáveis em larga escala devido aos avanços na computação (Morettin & Singer, 2024), (Hastie et al., 2009).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#deep-learning-aprendizado-profundo",
    "href": "modulo_1.html#deep-learning-aprendizado-profundo",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "3.2 Deep Learning (Aprendizado Profundo)",
    "text": "3.2 Deep Learning (Aprendizado Profundo)\nDeep Learning (DL) é um subconjunto do Machine Learning, uma evolução do Machine Learning baseada em redes neurais profundas, com múltiplas camadas ocultas. Permite que máquinas aprendam representações hierárquicas complexas de dados, como imagens, fala e texto. Esses modelos consistem em circuitos algébricos complexos com pesos ajustáveis, tipicamente organizados em muitas camadas, o que significa que os caminhos de computação das entradas para as saídas têm muitos passos (Zhang et al., 2023), (Boehmke & Greenwell, 2019).\nOs modelos de Deep Learning incluem diversas arquiteturas especializadas:\n\nRedes Neurais Densas (DNN): As formas mais básicas, com MLPs (Multi Layer Perceptrons) usando camadas ocultas para aprender relações complexas e não-lineares, ideais para classificação e regressão.\nRedes Neurais Convolucionais (CNNs): Especializadas em dados como imagens, usam filtros convolucionais para detectar padrões locais e hierarquias de características, tornando-as padrão em visão computacional.\nRedes Neurais Recorrentes (RNN): para séries temporais e outras sequências, incluindo LSTM (Long Short-Term Memory), projetadas para dados sequenciais, mantêm “memória” de entradas anteriores. LSTMs são uma variação que aprende dependências de longo prazo, ótimas para texto e áudio.\nModelos baseados em mecanismos de atenção, como Transformers, que se tornaram dominantes em Processamento de Linguagem Natural: Revolucionaram o PNL com o mecanismo de atenção, processando sequências em paralelo e capturando dependências de longo alcance, sendo a base de grandes modelos de linguagem (LLMs).\nRedes Neurais Bayesianas (BNNs): Incorporam estatística Bayesiana para modelar a incerteza nos pesos da rede, aprendendo distribuições de probabilidade. Isso permite quantificar a confiança nas previsões, sendo úteis onde a incerteza é crucial (ex: diagnósticos médicos).\n\nDL é geralmente uma escolha atraente quando o tamanho da amostra do conjunto de treinamento é extremamente grande e quando a interpretabilidade do modelo não é uma alta prioridade. O DL revolucionou o reconhecimento de padrões em áreas como visão computacional, Processamento de Linguagem Natural (PNL) e reconhecimento automático de fala. Softwares como Keras e TensorFlow são utilizados para implementar modelos de Deep Learning (James et al., 2021), (Morettin & Singer, 2024).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#ia-generativa",
    "href": "modulo_1.html#ia-generativa",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "3.3 IA Generativa",
    "text": "3.3 IA Generativa\nIA-Generativa é um Subcampo da IA que utiliza modelos probabilísticos e arquiteturas profundas para gerar novos dados (texto, imagens, vídeos, código) com distribuição semelhante aos dados de treinamento. Diferencia-se de modelos discriminativos por criar conteúdo original em vez de apenas classificar ou prever. Baseiam-se em:\n\nModelos de Difusão (Diffusion Models): Transformam ruído em dados estruturados através de processos iterativos (ex: Stable Diffusion).\nTransformers: Arquiteturas com self-attention capazes de capturar dependências de longo alcance (ex: GPT-4, Claude 3) .\nRedes Adversariais Generativas (GANs): Dois modelos competindo (gerador vs. discriminador) para produzir amostras realistas.\n\nÉ o “boom” atual da IA, revolucionando áreas criativas, educação, programação e produção de conteúdo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#agentes-de-ia-ia-autônoma",
    "href": "modulo_1.html#agentes-de-ia-ia-autônoma",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "3.4 Agentes de IA (IA Autônoma)",
    "text": "3.4 Agentes de IA (IA Autônoma)\nSão sistemas mais avançados e integrados que combinam modelos generativos, raciocínio, memória e ação em ambientes interativos. Exemplo: AutoGPT, BabyAGI, Devin. Eles planejam tarefas, acessam ferramentas (buscadores, código, banco de dados), interagem com usuários e adaptam seu comportamento. Representam o estágio mais recente da IA: autonomia e propósito guiado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#aprendizado-supervisionado",
    "href": "modulo_1.html#aprendizado-supervisionado",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "4.1 Aprendizado Supervisionado",
    "text": "4.1 Aprendizado Supervisionado\nNo aprendizado supervisionado, o modelo aprende a partir de um conjunto de dados que contém tanto as características (features, inputs, preditores, atributos, variável independente ou variável de entrada) de entrada quanto os valores de rótulo (target, label, predita, valor-alvo, variável dependente ou variável de resposta) ou classificação correspondentes. É como se o modelo tivesse um “chefe ditatorial” que lhe diz exatamente o que fazer em cada situação até que ele aprenda a mapear situações para ações. O objetivo é encontrar uma modelo que generalize bem para novos exemplos não vistos.\nVocê fornece ao algoritmo um grande conjunto de dados contendo exemplos de entradas e seus resultados desejados ou rótulos associados. O algoritmo então determina os melhores valores de parâmetros para um programa flexível, de forma a melhorar seu desempenho em relação a uma medida escolhida, usando o conjunto de dados para aprender esse mapeamento. O foco é aprender a prever algo desconhecido (o alvo) a partir de algo conhecido, as características.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#aprendizado-não-supervisionado",
    "href": "modulo_1.html#aprendizado-não-supervisionado",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "4.2 Aprendizado Não Supervisionado",
    "text": "4.2 Aprendizado Não Supervisionado\nEm Aprendizado não supervisionado os modelos aprendem a partir de dados não rotulados, ou seja, sem orientação explícita sobre quais são as saídas desejadas (não existe variável dependente). Os modelos são usados para descobrir padrões, estruturas e relacionamentos dentro dos dados sem a necessidade de supervisão humana.\nO aprendizado ocorre utilizando grandes volumes de dados sem a necessidade de esforço de rotulagem caro. Técnicas como “masked language modeling” preveem partes ocultas do texto usando partes circundantes, gerando a supervisão diretamente dos dados. Isso permite aprender representações (embeddings) para palavras ou textos. Em aprendizado não supervisionado, muitas vezes nos preocupamos com a incerteza, por exemplo, para determinar se um conjunto de medições é anômala ou não.\n\n  \n    \n      \n    \n    \n    \n  \n\nComaparção de ambos:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#o-que-é-um-modelo",
    "href": "modulo_1.html#o-que-é-um-modelo",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "5.1 O que é um Modelo?",
    "text": "5.1 O que é um Modelo?\nUm modelo é uma representação abstrata de um fenômeno real, construída com o objetivo de descrever, explicar, prever ou simular comportamentos observáveis. Essa representação pode assumir diferentes formas, desde equações matemáticas simples até estruturas computacionais complexas. A escolha do tipo de modelo depende fundamentalmente do objetivo da análise (predição, inferência ou explicação) e da natureza dos dados disponíveis. Em matemática, estatística e machine learning, modelos traduzem aspectos do mundo em estruturas formais, permitindo análise e tomada de decisão com base em dados.\n\n5.1.1 Modelo Matemático\n\n  \n    \n      \n    \n    \n    \n  \n\nOs modelos matemáticos representam relações determinísticas entre variáveis, sem considerar componentes aleatórios. São amplamente utilizados em física e engenharia, onde as relações entre grandezas são bem compreendidas e podem ser descritas por equações exatas (Hoffmann, 2017).\n\n5.1.1.1 Características principais:\n\nRelações fixas e determinísticas\nNão incorpora incerteza ou variabilidade\nParâmetros são constantes conhecidas\nFoco em representação exata do fenômeno\n\n\n\n5.1.1.2 Exemplo clássico:\nPara descrever como a posição de um corpo varia ao longo do tempo, é necessário relacionar cada instante a uma posição correspondente. Essa relação é chamada de função horária da posição e permite prever onde o corpo estará em qualquer momento do movimento. No caso de um movimento uniformemente acelerado, essa função é dada por:\n\\[\ns(t) = s_{0} + v_{0}t + \\dfrac{at^{2}}{2}\n\\]\nonde:\n\n\\(s(t) =\\) posição no tempo \\(t\\)\n\\(s_{0} =\\) posição inicial\n\\(v_{0} =\\) velocidade inicial\n\\(a =\\) aceleração\n\\(t =\\) tempo\n\n\n\n\n5.1.2 Modelo Estatístico\n\n  \n    \n      \n    \n    \n    \n  \n\nOs modelos estatísticos estendem os modelos matemáticos ao incorporar explicitamente um componente aleatório (geralmente um termo de erro ou resíduo), permitindo lidar com a incerteza inerente aos dados observacionais. São fundamentais em pesquisas científicas onde é necessário quantificar a variabilidade e fazer inferências sobre populações (Hoffmann, 2017).\n\n5.1.2.1 Características principais:\n\nComponente sistemático, ex: \\(\\mu = g(X; \\beta)\\)\nComponente aleatório, ex: \\(\\epsilon \\sim N(0, \\sigma^{2})\\)\n\n\n\n5.1.2.2 Exemplo - Regressão Linear Múltipla:\n\\[\nY = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^{2})\n\\]\nonde:\n\n\\(Y\\) = variável dependente\n\\(X_{1}\\) e \\(X_{2}\\) = variáveis independentes\n\\(\\beta_{0}\\), \\(\\beta_{1}\\) e \\(\\beta_{2}\\) = coeficientes ou parâmetros\n\\(\\epsilon\\) = componente aleatório\n\\(\\sigma^{2}\\) = variancia\n\n\n\n\n5.1.3 Modelo de Machine Learning\n\n  \n    \n      \n    \n    \n    \n  \n\nNo contexto de machine learning, um modelo é o “maquinário computacional para ingerir dados de um tipo e cuspir previsões de um tipo possivelmente diferente” (Zhang et al., 2023). Os modelos de machine learning muitas vezes se sobrepõem aos modelos estatísticos, ambos são estimados a partir de dados e buscam modelar a relação entre variáveis. O foco em ML pode ser a precisão preditiva em novos dados, mas também a inferência e a compreensão das relações nos dados, especialmente em campos como o Aprendizado Estatístico. Modelos de ML podem variar de métodos lineares interpretáveis (como regressão linear) a modelos complexos e menos interpretáveis, por vezes chamados de “caixas pretas”. No contexto de IA, modelos probabilísticos também são usados para inferência, calculando distribuições de probabilidade sob incerteza (Hastie et al., 2009), (James et al., 2021), (Norvig & Russell, 2021), (James et al., 2023).\n\n5.1.3.1 Principais categorias:\n\nModelos paramétricos: Assumem forma funcional fixa (ex: regressão linear múltipla)\nModelos não-paramétricos: Forma flexível determinada pelos dados (ex: árvores de decisão)\nModelos semi-paramétricos: Combinação das abordagens\n\n\n\n5.1.3.2 Exemplo - Rede Neural Artificial:\n\\[\n\\hat{y} = \\sigma(W_{2}\\sigma(W_{1}x+b_{1})+b_{2})\n\\]\nonde:\n\n\\(\\sigma\\) = função de ativação ReLU\n\\(W_{1}\\) e \\(W_{2}\\) = pesos\n\\(b_{1}\\) e \\(b_{2}\\) = bias\n\\(x\\) = entrada\n\\(\\hat{y}\\) = saída estimada\n\n\n\n\n5.1.4 Comparação Abrangente dos Três Tipos de Modelos\n\n\n\n\n\n\n\n\n\nCritério\nModelo Matemático\nModelo Estatístico\nModelo de ML\n\n\n\n\nFlexibilidade\nBaixa\nModerada\nAlta\n\n\nInterpretabilidade\nAlta\nAlta\nVariável\n\n\nTratamento de ruído\nNenhum\nExplícito\nImplícito\n\n\nRequisitos de dados\nNenhum\nModerados\nAltos\n\n\nComplexidade computacional\nBaixa\nModerada\nAlta\n\n\nParâmetros\nConstantes conhecidas\nEstimados dos dados\nAprendidos automaticamente\n\n\nObjetivo principal\nDescrição exata\nInferência e predição\nPredição e padrões complexos\n\n\nExemplos\nFunção horária da posição\nRegressão linear\nRedes neurais\n\n\n\nEm resumo, um modelo matemático define a estrutura determinística da relação, um modelo estatístico adiciona o componente aleatório necessário para a inferência, e um modelo de machine learning é o sistema computacional estimado a partir de dados para predição e/ou inferência, variando em sua complexidade e interpretabilidade.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#tipos-de-modelos-de-aprendizado-supervisionado",
    "href": "modulo_1.html#tipos-de-modelos-de-aprendizado-supervisionado",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "5.2 Tipos de Modelos de Aprendizado Supervisionado",
    "text": "5.2 Tipos de Modelos de Aprendizado Supervisionado\n\n  \n    \n      \n    \n    \n    \n  \n\nInformalmente, o processo de aprendizagem se parece com o seguinte. Primeiro, pegue uma grande coleção de exemplos cujas características são conhecidas e selecione deles um subconjunto aleatório, adquirindo os rótulos de verdade básica para cada um. Às vezes, esses rótulos podem ser dados disponíveis que já foram coletados (por exemplo, um paciente morreu no ano seguinte?) e outras vezes podemos precisar empregar anotadores humanos para rotular os dados (por exemplo, atribuindo imagens a categorias). Juntos, essas entradas e rótulos correspondentes compõem o conjunto de treinamento. Alimentamos o conjunto de dados de treinamento em um algoritmo de aprendizado supervisionado, uma função que recebe como entrada um conjunto de dados e gera como saída outra função: o modelo aprendido. Finalmente, podemos alimentar entradas não vistas anteriormente para o modelo aprendido, usando suas saídas como previsões do rótulo correspondente. O processo completo é desenhado na figura abaixo (Zhang et al., 2023).\n\n5.2.1 Regressão\n\n  \n    \n      \n    \n    \n    \n  \n\nRegressão é uma tarefa fundamental no aprendizado supervisionado. O principal objetivo é prever um valor numérico contínuo . Essencialmente, resolve problemas que perguntam “quanto?” ou “quantos?”. Modelos de regressão são treinados com dados contendo features (entradas) e rótulos (valores numéricos conhecidos). Exemplos comuns incluem prever preços de imóveis ou coordenadas de objetos em detecção de objetos [conversation history, 55]. O treinamento geralmente envolve a minimização de uma função de perda, como o erro quadrático médio (\\(MSE\\)). Técnicas de regularização são usadas para restringir os valores dos parâmetros e ajudar a evitar o overfitting. Modelos lineares simples podem ser estendidos para Regressão Polinomial adicionando features polinomiais, permitindo que o modelo capture relações não lineares complexas nos dados (Zhang et al., 2023), (Géron, 2021).\n\n\n5.2.2 Classificação\n\n  \n    \n      \n    \n    \n    \n  \n\nClassificação é uma tarefa fundamental no aprendizado supervisionado. O objetivo principal é prever a qual categoria (classe) discreta um exemplo pertence. Essencialmente, responde a perguntas de “qual categoria?”, diferentemente da regressão (“quanto?”). O modelo utiliza features (entradas) para fazer previsões sobre os rótulos (classes). Existem problemas de classificação binária (duas classes) e multiclasse (mais de duas). Frequentemente, os modelos fornecem probabilidades para cada classe, não apenas uma atribuição única. A função de perda comum usada para treinar modelos de classificação é a entropia cruzada. Exemplos incluem identificar spam em emails ou classificar imagens de objetos ou dígitos escritos à mão. É amplamente usada em Processamento de Linguagem Natural (PLN), como análise de sentimento. Modelos como Softmax Regression, MLPs, CNNs, RNNs e Transformers são aplicados em classificação (Zhang et al., 2023). (Géron, 2021).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  },
  {
    "objectID": "modulo_1.html#abordagem-de-modelagem-estatística-e-machine-learning",
    "href": "modulo_1.html#abordagem-de-modelagem-estatística-e-machine-learning",
    "title": "2  O que é Inteligência Artificial (IA)?",
    "section": "5.3 Abordagem de Modelagem: Estatística e Machine Learning",
    "text": "5.3 Abordagem de Modelagem: Estatística e Machine Learning\n\n  \n    \n      \n    \n    \n    \n  \n\nComo descreve Ali et al. (2024), no artigo Uma análise comparativa de aprendizado de máquina e métodos estatísticos para avaliar o desempenho do edifício: uma revisão sistemática e uma futura estrutura de benchmarking, e mostrado na figura acima, a abordagem estatística tradicional utiliza dados para construir uma relação matemática entre as entradas e a saída (variável alvo), levando em consideração suposições e regras estatísticas. Por outro lado, os algoritmos de Machine Learning (ML) aprendem diretamente com o conjunto de dados, identificando padrões que conectam a variável prevista aos preditores, geralmente sem necessidade de suposições rígidas.\nAlém disso, enquanto o modelo estatístico depende fortemente de conhecimento prévio e transparência no processo, os métodos de ML envolvem o aprendizado e treinamento de algoritmos, funcionando na maioria das vezes como uma “caixa preta” — ou seja, é difícil saber exatamente como o modelo foi formulado. Embora isso permita que o ML capture relações complexas e não lineares sem necessidade de amplo conhecimento de domínio, essa opacidade torna os modelos, em geral, pouco interpretáveis e mais difíceis de explicar.\nA figura reforça essas diferenças: à esquerda, a modelagem estatística tradicional segue um fluxo direto, baseado em suposições explícitas; à direita, a modelagem com ML divide-se em fases de aprendizagem e de previsão, mostrando como o modelo precisa ser treinado previamente para gerar um “modelo treinado” que, então, pode ser aplicado a novos dados.\nApesar de suas limitações e custos computacionais elevados, os métodos de ML podem produzir resultados mais robustos em contextos complexos. Assim, é fundamental comparar e avaliar cuidadosamente a adequação de ambas as abordagens. A escolha entre as abordagens depende do objetivo (inferência vs. previsão), da natureza dos dados (linearidade, tamanho) e da necessidade de interpretabilidade do modelo. A integração de ambas as abordagens também é vista como benéfica em muitos campos, como a medicina (Rajula et al., 2020).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Módulo 1</span>"
    ]
  }
]