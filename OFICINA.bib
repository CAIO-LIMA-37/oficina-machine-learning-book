
@book{boehmke_hands-machine_2019,
	address = {Boca Raton},
	edition = {1st edition},
	title = {Hands-{On} {Machine} {Learning} with {R}},
	isbn = {978-1-138-49568-5},
	abstract = {Hands-on Machine Learning with R provides a practical and applied approach to learning and developing intuition into today’s most popular machine learning methods. This book serves as a practitioner’s guide to the machine learning process and is meant to help the reader learn to apply the machine learning stack within R, which includes using various R packages such as glmnet, h2o, ranger, xgboost, keras, and others to effectively model and gain insight from their data. The book favors a hands-on approach, providing an intuitive understanding of machine learning concepts through concrete examples and just a little bit of theory. Throughout this book, the reader will be exposed to the entire machine learning process including feature engineering, resampling, hyperparameter tuning, model evaluation, and interpretation. The reader will be exposed to powerful algorithms such as regularized regression, random forests, gradient boosting machines, deep learning, generalized low rank models, and more! By favoring a hands-on approach and using real word data, the reader will gain an intuitive understanding of the architectures and engines that drive these algorithms and packages, understand when and how to tune the various hyperparameters, and be able to interpret model results. By the end of this book, the reader should have a firm grasp of R’s machine learning stack and be able to implement a systematic approach for producing high quality modeling results.Features:· Offers a practical and applied introduction to the most popular machine learning methods.· Topics covered include feature engineering, resampling, deep learning and more.· Uses a hands-on approach and real world data.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {Boehmke, Brad and Greenwell, Brandon M.},
	month = nov,
	year = {2019},
}

@book{norvig_artificial_2021,
	address = {Boston},
	edition = {4th edition},
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}, {Global} {Edition}},
	isbn = {978-1-292-40113-3},
	shorttitle = {Artificial {Intelligence}},
	abstract = {Thelong-anticipated revision of ArtificialIntelligence: A Modern Approach explores the full breadth and depth of the field of artificialintelligence (AI). The 4th Edition brings readers up to date on the latest technologies,presents concepts in a more unified manner, and offers new or expanded coverageof machine learning, deep learning, transfer learning, multi agent systems,robotics, natural language processing, causality, probabilistic programming,privacy, fairness, and safe AI.},
	language = {English},
	publisher = {Pearson},
	author = {Norvig, Peter and Russell, Stuart},
	month = may,
	year = {2021},
}

@book{james_introduction_2021,
	address = {New York},
	edition = {Second Edition 2021},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R}},
	isbn = {978-1-07-161417-4},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, deep learning, survival analysis, multiple testing, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.This Second Edition features new chapters on deep learning, survival analysis, and multiple testing, as well as expanded treatments of naïve Bayes, generalized linear models, Bayesian additive regression trees, and matrix completion. R code has been updated throughout to ensure compatibility.},
	language = {English},
	publisher = {Springer},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	month = jul,
	year = {2021},
}

@book{james_introduction_2023,
	address = {Cham},
	series = {Springer {Texts} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {Python}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-38746-3 978-3-031-38747-0},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	url = {https://link.springer.com/10.1007/978-3-031-38747-0},
	language = {en},
	urldate = {2025-05-05},
	publisher = {Springer International Publishing},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and Taylor, Jonathan},
	year = {2023},
	doi = {10.1007/978-3-031-38747-0},
	keywords = {data mining, inference, Python, Python software, statistical learning, supervised learning, unsupervsied learning},
}

@book{dekking_modern_2007,
	address = {London},
	title = {A {Modern} {Introduction} to {Probability} and {Statistics}: {Understanding} {Why} and {How}},
	isbn = {978-1-85233-896-1},
	shorttitle = {A {Modern} {Introduction} to {Probability} and {Statistics}},
	abstract = {Suitable for self study Use real examples and real data sets that will be familiar to the audience Introduction to the bootstrap is included - this is a modern method missing in many other books},
	language = {Inglês},
	publisher = {Springer Nature BV},
	author = {Dekking, F. M.},
	month = feb,
	year = {2007},
}

@book{denis_univariate_2020,
	address = {Hoboken, NJ},
	edition = {1ª edição},
	title = {Univariate, {Bivariate}, and {Multivariate} {Statistics} {Using} {R}: {Quantitative} {Tools} for {Data} {Analysis} and {Data} {Science}},
	isbn = {978-1-119-54993-2},
	shorttitle = {Univariate, {Bivariate}, and {Multivariate} {Statistics} {Using} {R}},
	abstract = {A practical source for performing essential statistical analyses and data management tasks in RUnivariate, Bivariate, and Multivariate Statistics Using R offers a practical and very user-friendly introduction to the use of R software that covers a range of statistical methods featured in data analysis and data science. The author-- a noted expert in quantitative teaching --has written a quick go-to reference for performing essential statistical analyses and data management tasks in R. Requiring only minimal prior knowledge, the book introduces concepts needed for an immediate yet clear understanding of statistical concepts essential to interpreting software output. The author explores univariate, bivariate, and multivariate statistical methods, as well as select nonparametric tests. Altogether a hands-on manual on the applied statistics and essential R computing capabilities needed to write theses, dissertations, as well as research publications. The book is comprehensive in its coverage of univariate through to multivariate procedures, while serving as a friendly and gentle introduction to R software for the newcomer. This important resource: Offers an introductory, concise guide to the computational tools that are useful for making sense out of data using R statistical softwareProvides a resource for students and professionals in the social, behavioral, and natural sciencesPuts the emphasis on the computational tools used in the discovery of empirical patternsFeatures a variety of popular statistical analyses and data management tasks that can be immediately and quickly applied as needed to research projectsShows how to apply statistical analysis using R to data sets in order to get started quickly performing essential tasks in data analysis and data scienceWritten for students, professionals, and researchers primarily in the social, behavioral, and natural sciences, Univariate, Bivariate, and Multivariate Statistics Using R offers an easy-to-use guide for performing data analysis fast, with an emphasis on drawing conclusions from empirical observations. The book can also serve as a primary or secondary textbook for courses in data analysis or data science, or others in which quantitative methods are featured.},
	language = {Inglês},
	publisher = {Wiley},
	author = {Denis, Daniel J.},
	month = apr,
	year = {2020},
}

@book{geron_maos_2021,
	edition = {1ª edição},
	title = {Mãos à {Obra}: {Aprendizado} de {Máquina} com {Scikit}-{Learn}, {Keras} \& {TensorFlow}: {Conceitos}, {Ferramentas} e {Técnicas} {Para} a {Construção} de {Sistemas} {Inteligentes}},
	isbn = {978-85-508-1548-0},
	shorttitle = {Mãos à {Obra}},
	abstract = {Por meio de uma série de avanços tecnológicos, o aprendizado de máquina tem estimulado todos os campos de atuação em que se insere. Hoje em dia, até mesmo os programadores que não sabem quase nada sobre esses avanços podem usar ferramentas simples e eficientes para implementar programas capazes de aprender com os dados. A edição atualizada deste best-seller apresenta exemplos concretos, pouca teoria e frameworks Python para serem usados em produção, visando ajudá-lo a entender intuitivamente os conceitos e ferramentas para a construção de sistemas inteligentes. Com isso, você aprenderá uma variedade de técnicas que pode usar rapidamente. Como cada capítulo tem exercícios para que você possa praticar o que aprendeu, basta ganhar experiência com programação para começar. Todos os códigos estão disponíveis no GitHub. A obra também foi atualizada com a TensorFlow 2 e a versão mais recente da Scikit-Learn.• Compreenda os fundamentos do aprendizado de máquina por meio de um projeto end-to-end usando a Scikit-Learn e o Pandas. • Aprenda a detecção de objetos, segmentação semântica, mecanismos de atenção, modelos de linguagem, GANs e muito mais. • Explore a Keras API, a API oficial de alto nível da TensorFlow 2. • Disponibilize em produção modelos TensorFlow usando a Data API, API de estratégias de distribuição, TF Transform e TF-Serving. • Implementação no Google Cloud AI Platform ou em dispositivos móveis. • Explore técnicas de aprendizado não supervisionado, como redução de dimensionalidade, clusterização e detecção de anomalias. • Crie agentes de aprendizagem autônomos por meio do aprendizado por reforço com a biblioteca TF-Agents.},
	language = {Português},
	publisher = {Alta Books},
	author = {Géron, Aurélien},
	month = sep,
	year = {2021},
}

@book{sandoval_introducao_2021,
	title = {Introducao {A} {Inferencia} {Estatistica}},
	isbn = {978-85-85818-82-1},
	abstract = {Este livro é um material básico para um curso introdutório de Inferência Estatística, sendo dada maior ênfase a problemas teóricos. Destina-se, principalmente, a alunos de Bacharelado em Estatística exigindo-se conhecimentos básicos de probabilidade e cálculo. O livro está dividido em seis capítulos tendo no final de cada um, uma série de exercícios.},
	language = {Português},
	author = {Sandoval, Heleno Bolfarine e Mônica Carneiro},
	month = jul,
	year = {2021},
}

@misc{noauthor_o_nodate,
	title = {O que são {Modelos} {Paramétricos} e {Não} {Paramétricos} em machine learning - {IA} {Com} {Café}},
	url = {https://iacomcafe.com.br/modelos-parametricos-nao-parametricos/},
	urldate = {2025-05-05},
	file = {O que são Modelos Paramétricos e Não Paramétricos em machine learning - IA Com Café:C\:\\Users\\Pedro Caio\\Zotero\\storage\\UGFVQ2AI\\modelos-parametricos-nao-parametricos.html:text/html},
}

@article{ali_comparative_2024,
	title = {A comparative analysis of machine learning and statistical methods for evaluating building performance: {A} systematic review and future benchmarking framework},
	volume = {252},
	issn = {0360-1323},
	shorttitle = {A comparative analysis of machine learning and statistical methods for evaluating building performance},
	url = {https://www.sciencedirect.com/science/article/pii/S0360132324001100},
	doi = {10.1016/j.buildenv.2024.111268},
	abstract = {The utilization of machine learning (ML) techniques is increasingly prevalent in the domain of building performance evaluation. This trend is primarily driven by ML's capacity to capture intricate relationships between building attributes and performance metrics, such as energy consumption and comfort levels. However, the comparative merits of ML techniques and traditional statistical methods, such as linear and logistic regression, which are typically more cost-effective and interpretable, remains uncertain. This study presents a systematic comparison between ML and statistical methods in the assessment of building performance, considering factors such as model complexity, interpretability, required expertise, performance disparities, and computational costs. Findings indicate that, in most scenarios, ML techniques outperform statistical methods. Nevertheless, there are notable instances where statistical methods can compete, highlighting the context-dependent nature of technique selection. Furthermore, this research introduces a novel Python-based framework with a user-friendly spreadsheet interface designed for the evaluation and benchmarking of ML and statistical methods in research settings. The developed framework can be easily customized for ML evaluation and benchmarking in diverse fields, including production, logistics, supply chain management, and others.},
	urldate = {2025-05-05},
	journal = {Building and Environment},
	author = {Ali, Abdulrahim and Jayaraman, Raja and Azar, Elie and Maalouf, Maher},
	month = mar,
	year = {2024},
	keywords = {AutoML, Building performance, Machine learning, Occupant comfort, Statistical methods},
	pages = {111268},
	file = {ScienceDirect Snapshot:C\:\\Users\\Pedro Caio\\Zotero\\storage\\BDSQAXAX\\S0360132324001100.html:text/html},
}

@article{rajula_comparison_2020,
	title = {Comparison of {Conventional} {Statistical} {Methods} with {Machine} {Learning} in {Medicine}: {Diagnosis}, {Drug} {Development}, and {Treatment}},
	volume = {56},
	issn = {1648-9144},
	url = {https://www.mdpi.com/1648-9144/56/9/455},
	doi = {10.3390/medicina56090455},
	abstract = {Futurists have anticipated that novel autonomous technologies, embedded with machine learning (ML), will substantially influence healthcare. ML is focused on making predictions as accurate as possible, while traditional statistical models are aimed at inferring relationships between variables. The benefits of ML comprise flexibility and scalability compared with conventional statistical approaches, which makes it deployable for several tasks, such as diagnosis and classification, and survival predictions. However, much of ML-based analysis remains scattered, lacking a cohesive structure. There is a need to evaluate and compare the performance of well-developed conventional statistical methods and ML on patient outcomes, such as survival, response to treatment, and patient-reported outcomes (PROs). In this article, we compare the usefulness and limitations of traditional statistical methods and ML, when applied to the medical field. Traditional statistical methods seem to be more useful when the number of cases largely exceeds the number of variables under study and a priori knowledge on the topic under study is substantial such as in public health. ML could be more suited in highly innovative fields with a huge bulk of data, such as omics, radiodiagnostics, drug development, and personalized treatment. Integration of the two approaches should be preferred over a unidirectional choice of either approach.},
	number = {9},
	journal = {Medicina},
	author = {Rajula, Hema Sekhar Reddy and Verlato, Giuseppe and Manchia, Mirko and Antonucci, Nadia and Fanos, Vassilios},
	year = {2020},
}

@article{takefuji_urgent_2025,
	title = {An urgent call for robust statistical methods in reliable feature importance analysis across machine learning},
	volume = {446},
	issn = {0021-9517},
	url = {https://www.sciencedirect.com/science/article/pii/S0021951725001630},
	doi = {10.1016/j.jcat.2025.116098},
	abstract = {Accurate analytical outcomes in machine learning are contingent on error-free calculations and a solid understanding of foundational principles. A notable challenge arises from the lack of ground truth values for validation, complicating the assessment of feature importance, especially when employing linear models with parametric assumptions. This paper critiques the use of Pearson correlation and feature importances derived from Gradient Boosting Regressor (GBR), emphasizing their limitations in analyzing nonlinear and nonparametric data. We propose robust statistical methods, such as Spearman’s correlation and Kendall’s tau, as alternatives for capturing complex relationships while providing essential directional information. Additionally, attention to Variance Inflation Factor (VIF) is crucial for mitigating feature inflation. By addressing these concerns, researchers can achieve more reliable analyses and deeper insight into variable relationships.},
	urldate = {2025-05-05},
	journal = {Journal of Catalysis},
	author = {Takefuji, Yoshiyasu},
	month = jun,
	year = {2025},
	keywords = {Machine learning, Statistical methods, Feature importance, Ground truth values, Nonlinear analysis, Pearson correlation},
	pages = {116098},
	file = {ScienceDirect Snapshot:C\:\\Users\\Pedro Caio\\Zotero\\storage\\AXSJZH37\\S0021951725001630.html:text/html},
}

@article{murdoch_definitions_2019,
	title = {Definitions, methods, and applications in interpretable machine learning},
	volume = {116},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1900654116},
	doi = {10.1073/pnas.1900654116},
	abstract = {The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.},
	number = {44},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Murdoch, W. James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
	year = {2019},
	note = {\_eprint: https://www.pnas.org/doi/pdf/10.1073/pnas.1900654116},
	pages = {22071--22080},
}

@book{zhang_dive_2023,
	address = {Cambridge New York Port Melbourne New Delhi Singapore},
	title = {Dive {Into} {Deep} {Learning}},
	isbn = {978-1-00-938943-3},
	abstract = {Deep learning has revolutionized pattern recognition, introducing tools that power a wide range of technologies in such diverse ﬁelds as computer vision, natural language processing, and automatic speech recognition. Applying deep learning requires you to simultaneously understand how to cast a problem, the basic mathematics of modeling, the algorithms for ﬁtting your models to data, and the engineering techniques to implement it all. This book is a comprehensive resource that makes deep learning approachable, while still providing sufficient technical depth to enable engineers, scientists, and students to use deep learning in their own work. No previous background in machine learning or deep learning is required--every concept is explained from scratch and the appendix provides a refresher on the mathematics needed. Runnable code is featured throughout, allowing you to develop your own intuition by putting key ideas into practice.},
	language = {Inglês},
	publisher = {Cambridge University Press},
	author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
	month = dec,
	year = {2023},
}

@book{hastie_elements_2009,
	address = {New York, NY},
	title = {The {Elements} of {Statistical} {Learning}: {Data} {Mining}, {Inference}, and {Prediction}, {Second} {Edition}},
	isbn = {978-0-387-84858-7},
	shorttitle = {The {Elements} of {Statistical} {Learning}},
	abstract = {This book describes the important ideas in a variety of fields such as medicine, biology, finance, and marketing in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of colour graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorisation, and spectral clustering. There is also a chapter on methods for "wide'' data (p bigger than n), including multiple testing and false discovery rates.},
	language = {Inglês},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
}

@book{morettin_estatistica_2024,
	address = {RIO DE JANEIRO, RJ},
	title = {Estatística e {Ciência} de {Dados}},
	isbn = {978-85-216-3900-8},
	abstract = {Nesta segunda edição, o clássico e referenciado Estatística e Ciência de Dados continua sua trajetória de sucesso e pioneirismo ao abordar esse tema tão atual, sob o ponto de vista estatístico e computacional. Desenvolvido pelos consagrados autores Pedro Morettin e Julio Singer, combina, de maneira didática e objetiva, os fundamentos de análise exploratória de dados – extremamente importantes para a compreensão da Ciência de Dados – aos principais métodos utilizados na área.Os autores apresentam as ideias que fundamentam os algoritmos de suporte vetorial, árvores de decisão, florestas aleatórias e redes neurais, em um contexto que introduz as principais aplicações do tema (previsão, classificação, redução da dimensionalidade e agrupamento). Há vários exemplos práticos provenientes de análises de dados reais.O conteúdo foi completamente revisto e atualizado, e foram incluídos novos exemplos e uma breve descrição sobre redes generativas adversárias.Diferenciais:• Promove integração entre os conceitos de Estatística, Computação e Ciência de Dados.• Exibe conjuntos de dados e comandos do software R utilizados para as análises ao longo de todo o texto.• Oferece inúmeros exemplos práticos, sendo a maioria proveniente de análises de dados reais.• Apresenta apêndices com conceitos básicos de simulação e otimização, e também sobre algoritmos para dados aumentados.?},
	language = {Português},
	publisher = {LTC},
	author = {Morettin, Pedro Alberto and Singer, Julio da Motta},
	month = may,
	year = {2024},
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures} (with comments and a rejoinder by the author)},
	volume = {16},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Statistical {Modeling}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	number = {3},
	urldate = {2025-05-20},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	month = aug,
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {199--231},
}

@book{wasserman_all_2008,
	address = {New York, NY},
	title = {All of {Statistics}: {A} {Concise} {Course} in {Statistical} {Inference}},
	isbn = {978-0-387-40272-7},
	shorttitle = {All of {Statistics}},
	abstract = {Taken literally, the title "All of Statistics" is an exaggeration. But in spirit, the title is apt, as the book does cover a much broader range of topics than a typical introductory book on mathematical statistics. This book is for people who want to learn probability and statistics quickly. It is suitable for graduate or advanced undergraduate students in computer science, mathematics, statistics, and related disciplines. The book includes modern topics like nonparametric curve estimation, bootstrapping, and clas� sification, topics that are usually relegated to follow-up courses. The reader is presumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. Statistics, data mining, and machine learning are all concerned with collecting and analyzing data. For some time, statistics research was con� ducted in statistics departments while data mining and machine learning re� search was conducted in computer science departments. Statisticians thought that computer scientists were reinventing the wheel. Computer scientists thought that statistical theory didn't apply to their problems. Things are changing. Statisticians now recognize that computer scientists are making novel contributions while computer scientists now recognize the generality of statistical theory and methodology. Clever data mining algo� rithms are more scalable than statisticians ever thought possible. Formal sta� tistical theory is more pervasive than computer scientists had realized.},
	language = {Inglês},
	publisher = {Springer},
	author = {Wasserman, Larry A.},
	year = {2008},
}

@book{hoffmann_alise_2017,
	title = {Análise de regressão: uma introdução à econometria},
	copyright = {Copyright (c) 2016 Universidade de São Paulo. Escola Superior de Agricultura Luiz de Queiroz},
	isbn = {978-85-921057-0-9},
	shorttitle = {Análise de regressão},
	url = {https://www.livrosabertos.abcd.usp.br/portaldelivrosUSP/catalog/book/73},
	abstract = {O autor apresenta métodos estatísticos para disciplinas de econometria e análise de regressão ministradas na ESALQ-USP e aplicadas em diversas áreas \&nbsp;como: pesquisas econômicas, biologia, física ou engenharia},
	language = {pt},
	urldate = {2025-05-20},
	publisher = {Portal de Livros Abertos da USP},
	author = {Hoffmann, Rodolfo},
	month = sep,
	year = {2017},
	doi = {10.11606/9788592105709},
	note = {Publication Title: Portal de Livros Abertos da USP},
	keywords = {Análise de regressão, Econometria, Econometrics, Regression analysis},
	file = {Full Text PDF:C\:\\Users\\Pedro Caio\\Zotero\\storage\\9TGFG2DD\\Hoffmann - 2017 - Análise de regressão uma introdução à econometria.pdf:application/pdf},
}
